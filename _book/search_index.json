[
["switching-autoregressive-system.html", "Chapter 3 Switching autoregressive system 3.1 Model 3.2 Inference", " Chapter 3 Switching autoregressive system In this chapter, we focus on a more complex system involving autoregressive structure. We still focus on a time series \\(y_0, \\dots, y_n\\) of values in \\(\\mathbb{R}^d\\). However, it is now supposed that the time series dynamics could change through time, according to an unobserved stochastic process in a discrete space. This unobserved process might model different regimes of the dynamics (see Rabiner (1989) for selected applications). 3.1 Model Taking the same notations and dimensions as in equation (??) We assume that these observations are realisations of random variables \\(Y_0,\\dots, Y_n\\) such that: \\[\\begin{align*} Z_0 &amp;\\sim \\chi_{0, Z}(\\cdot)\\\\ Z_t \\vert Z_{t - 1} &amp;\\sim p(z_t \\vert Z_{t - 1}) \\\\ Y_0 &amp;\\sim \\chi_{0, Y}(\\cdot \\vert Z_0), \\\\ Y_t \\vert Z_t &amp;= m(Z_t) + \\mathbf{A}(Z_t)Y_{t -1} + E_t,~1\\leq t \\leq n \\end{align*}\\] where \\(\\left\\lbrace Z_t \\right\\rbrace_{0\\leq t \\leq n}\\) is an homogeneous Markov chain taking value on the finite space \\(\\mathbb{K} = \\lbrace1,\\dots, K \\rbrace\\), and of transition matrix denoted by \\(\\mathbf{P}\\), \\(\\lbrace m(k)\\in\\mathbb{R}^d,~\\mathbf{A}(k)\\in \\mathcal{M}_{d\\times d}\\rbrace_{k = 1,\\dots, K}\\) are unknown parameters. \\(\\chi_{0, Z}(\\cdot)\\) and \\(\\chi_{0, Y}(\\cdot \\vert Z_0)\\) are some probability distributions over \\(\\mathbb{K}\\) and \\(\\mathbb{R}^d\\) \\(p(z_t\\vert Z_{t-1})\\) is the law of \\(Z_t\\) condtionnally to \\(Z_{t - 1}\\) (here the line of \\(\\mathbf{P}\\) given by \\(Z_{t - 1}\\)). \\(E_t\\) is a random vector such that: \\[\\begin{equation*} E_t \\overset{ind.}{\\sim} \\mathcal{N}\\left(0, \\mathbf{\\Sigma}\\right). \\end{equation*}\\] where \\(\\mathbf{\\Sigma}\\) is \\(d\\times d\\) covariance matrix. In this context, the set of unknown parameters is given by \\[\\theta = \\left\\lbrace \\mathbf{P}, m(k),~\\mathbf{A}(k), \\mathbf{\\Sigma}\\right \\rbrace_{k = 1,\\dots, K}.\\] 3.2 Inference In this context, the inference task is twofold: Obtaining maximum likelihood estimate of \\(\\theta\\); Retracing the hidden sequence \\(Z_0,\\dots Z_n\\) given the observations \\(Y_{0:n}\\). It is well known that these two tasks are indeed complementary. A common way to solve these problems is the Expectation Maximization (EM) algorithm (Dempster, Laird, and Rubin 1977). The algorithm is shortly depicted here. 3.2.1 Comment about notations In the following, we use the notation \\(p\\) for a generic probability distribution. The law to which it refers is explicit through arguments. For instance \\(p(y_{0:n} \\vert z_{0:n})\\) is the p.d.f. of a Gaussian vector, the random vector \\(Y_{0:n}\\vert Z_{0:n}\\), and \\(p(z_t\\vert z_{t - 1})\\) is the law of the discrete random variable \\(Z_{t} \\vert Z_{t - 1}\\) evaluated at \\(z_t\\) and \\(z_{t -1}\\). In this context, \\(p(z_t\\vert z_{t - 1}) = \\mathbb{P}(Z_t = z_t \\vert \\lbrace Z_{t-1} = z_{t -1}\\rbrace.\\) 3.2.2 Likelihood A straightforward way to compute the likelihood in this model can be obtained, just using the Markov properties of this model: \\[\\begin{align} L(\\theta \\vert y_{0:n}) &amp;:= p(y_{0:n} \\vert \\theta) \\nonumber \\\\ &amp;= \\sum_{z_{0:n}} p(y_{0:n}, z_{0:n}) \\nonumber \\\\ &amp;= \\sum_{z_{0:n}} p(z_{0:n})p(y_{0:n}\\vert z_{0:n}) \\nonumber \\\\ &amp;= \\sum_{z_{0:n}} p(z_0 \\vert \\theta) p(y_0\\vert z_0, \\theta) \\prod_{t = 1}^n p(z_{t} \\vert z_{t - 1}, \\theta)p(y_{t}\\vert y_{t -1}, z_{t}, \\theta) \\tag{3.1}. \\end{align}\\] For a known \\(\\theta\\), every term in (3.1) can be computed. However, in a general setting, there exists \\(K^{n + 1}\\) possible sequences \\(z_{0:n}\\), which makes this direct computation hardly feasible for any common values of \\(n\\). 3.2.3 Complete log-likelihood A workaround to find the maximum likelihood estimate is the EM algorithm. In this context, we focus on a different function, the complete log-likelihood, i.e. the likelihood of the completed observations (what we wish we could observe), \\((y_{0:n}, x_{0:n})\\), we have that: \\[\\begin{align} \\ell(\\theta \\vert y_{0:n}, z_{0:n}) :=&amp; \\log p(y_{0:n}, z_{0:n} \\vert \\theta) \\nonumber \\\\ =&amp; \\log p(y_{0:n}, z_{0:n}) \\nonumber \\\\ =&amp; \\log p(z_{0:n}) + \\log p(y_{0:n}\\vert z_{0:n}) \\nonumber \\\\ =&amp; \\log p(z_0 \\vert \\theta) + \\log p(y_0\\vert z_0, \\theta) \\nonumber \\\\ &amp;+ \\sum_{t = 1}^n \\log p(z_{t} \\vert z_{t - 1}, \\theta) + \\sum_{t = 1}^n \\log p(y_{t}\\vert y_{t -1}, z_{t}, \\theta) \\tag{3.2}. \\end{align}\\] For a given set of parameters, say \\(\\theta^{(0)}\\), let’s consider the following function of \\(\\theta\\): \\[\\begin{equation} Q(\\theta \\vert \\theta_0) :=&amp; \\mathbb{E}[\\ell(\\theta \\vert Y_{0:n}, Z_{0:n}) \\vert Y_{0:n} = y_{0:n}, \\theta^{(0)}] \\tag{3.3} \\end{equation}\\] \\[\\begin{align} Q(\\theta \\vert \\theta_0) :=&amp; \\mathbb{E}[\\ell(\\theta \\vert Y_{0:n}, Z_{0:n}) \\vert Y_{0:n} = y_{0:n}, \\theta^{(0)}]\\nonumber \\\\ =&amp; \\sum_{z_{0:n}} \\ell(\\theta \\vert y_{0:n}, z_{0:n}) p(z_{0:n} \\vert y_{0:n}, \\theta^{(0)}) \\text{d} z_{0:n} \\nonumber \\\\ =&amp; \\sum_{k = 1}^K p(z_0 = k \\vert y_{0:n}, \\theta^{(0)})\\left(\\log p(z_0 = k \\vert \\theta) + \\log(p(y_0 \\vert z_0 = k, \\theta))\\right) \\nonumber \\\\ &amp; + \\sum_{k = 1}^K\\sum_{k&#39; = 1}^K \\sum_{t = 1}^n p(z_{t-1} = k, z_{t} = k&#39;\\vert y_{0:n}, \\theta^{(0)}) \\log p(z_{t} \\vert z_{t - 1} \\vert \\theta) \\nonumber \\\\ &amp; + \\sum_{k = 1}^K \\sum_{t = 1}^n p(z_t = k\\vert y_{0:n}, \\theta^{(0)}) \\log p(y_{t} \\vert z_{t} = k, \\theta) \\nonumber \\end{align}\\] References "]
]

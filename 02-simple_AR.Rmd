---
output:
  pdf_document: default
  html_document: default
editor_options: 
  chunk_output_type: console
---

# Multivariate autoregressive model  {#simpleAR}

In this chapter, we focus on the case where observations consist in a multivariate time series $y_0, \dots, y_n$ such that for any $0\leq t \leq n$, $y_t \in \mathbb{R}^d$, we denote:
$$y_t = 
\begin{pmatrix}
y_{t,1}\\
\vdots\\
y_{t, d}
\end{pmatrix}$$

## Model

We assume that these observations are realisations of random variables $Y_0,\dots, Y_n$ such that:
\begin{align}
Y_0 &\sim \chi_0(\cdot),\nonumber \\
Y_t &= m + \mathbf{A}Y_{t -1} + E_t,~1\leq t \leq n (\#eq:AR-simple)
\end{align}
where  $\chi_0$ is some probability distribution over $\mathbb{R}^d$, $m\in\mathbb{R}^d$ and $\mathbf{A}\in \mathcal{M}_{d\times d}$ are parameters, $E_t$ is a $d-$dimensionnal vector such that:
\begin{equation*}
E_t \overset{ind.}{\sim} \mathcal{N}\left(0, \mathbf{\Sigma}\right).
\end{equation*}

## Inference

In this simple context, inference consists in finding the maximum likelihood estimates of unknown parameters\footnote{In the case where multiple time series are observed, unknown parameters for the initial distribution $\chi_0(\cdot)$ could be considered} $\hat{m}$, $\hat{\mathbf{A}}$ and $\mathbf{\Sigma}$.

Inference is straightforward here as we can recognize in \@ref(eq:AR-simple) a multivariate linear model:
$$\mathbf{Y} = \mathbf{XB} + \mathbf{E},$$
where
\begin{align*}
\mathbf{Y} &=
\begin{pmatrix}
Y_1'\\
\vdots\\
Y_n'
\end{pmatrix} \in \mathcal{M}_{n \times d},\\
\mathbf{X} &=
\begin{pmatrix}
1 & Y_0'\\
\vdots\\
1 & Y_{n-1}'
\end{pmatrix} \in \mathcal{M}_{n \times (d+1)},\\
\mathbf{B} &=
\begin{pmatrix}
m'\\
A'
\end{pmatrix} \in \mathcal{M}_{(d + 1) \times d},\\
\mathbf{E} &=
\begin{pmatrix}
E_1'\\
\vdots\\
E_n'
\end{pmatrix} \in \mathcal{M}_{n \times d}.
\end{align*}
Thus, $\hat{m}$ and $\hat{\mathbf{A}}$ can be obtained using the classical estimate
\begin{equation}
\hat{\mathbf{B}} = \left(\mathbf{X'X}\right)^{-1}\mathbf{X}'\mathbf{Y}, (\#eq:AR-simple-B-hat)
\end{equation}
and $\hat{\mathbf{\Sigma}}$ is then obtained classicaly as:
\begin{equation}
\hat{\mathbf{\Sigma}} = \frac{1}{n} \sum_{t = 1}^n \left(Y_t - \hat{m} - \hat{\mathbf{A}} Y_{t - 1}\right) \left(Y_t - \hat{m} - \hat{\mathbf{A}} Y_{t - 1}\right)' (\#eq:AR-simple-Sigma-hat)
\end{equation}
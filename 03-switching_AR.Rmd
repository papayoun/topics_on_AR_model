---
output:
  pdf_document: default
  html_document: default
---
# Switching autoregressive system

In this chapter, we focus on a more complex system involving autoregressive structure. We still focus on a time series $y_0, \dots, y_n$ of values in $\mathbb{R}^d$. However, it is now supposed that the time series dynamics could change through time, according to an unobserved stochastic process in a discrete space. 
This unobserved process might model different regimes of the dynamics (see @rabiner1989tutorial for selected applications).

## Model

Taking the same notations and dimensions as in equation \@ref(eq:AR-simple)
We assume that these observations are realisations of random variables $Y_0,\dots, Y_n$ such that:
\begin{align*}
Z_0 &\sim \chi_{0, Z}(\cdot)\\
Z_t \vert Z_{t - 1} &\sim p(z_t \vert Z_{t - 1}) \\
Y_0 &\sim \chi_{0, Y}(\cdot \vert Z_0), \\
Y_t \vert Z_t &= m(Z_t) + \mathbf{A}(Z_t)Y_{t -1} + E_t,~1\leq t \leq n 
\end{align*}
where 

- $\left\lbrace Z_t \right\rbrace_{0\leq t \leq n}$ is an homogeneous Markov chain taking value on the finite space $\mathbb{K} = \lbrace1,\dots, K \rbrace$, and of transition matrix denoted by $\mathbf{P}$,
- $\lbrace m(k)\in\mathbb{R}^d,~\mathbf{A}(k)\in \mathcal{M}_{d\times d}\rbrace_{k = 1,\dots, K}$ are unknown parameters.
- $\chi_{0, Z}(\cdot)$ and $\chi_{0, Y}(\cdot \vert Z_0)$ are some probability distributions over $\mathbb{K}$ and $\mathbb{R}^d$
- $p(z_t\vert Z_{t-1})$  is the law of $Z_t$ condtionnally to $Z_{t - 1}$ (here the line of $\mathbf{P}$ given by $Z_{t - 1}$).
- $E_t$ is a random vector such that: 
\begin{equation*}
E_t \overset{ind.}{\sim} \mathcal{N}\left(0, \mathbf{\Sigma}\right).
\end{equation*} where $\mathbf{\Sigma}$ is $d\times d$ covariance matrix.

In this context, the set of unknown parameters is given by 
$$\theta = \left\lbrace \mathbf{P}, m(k),~\mathbf{A}(k), \mathbf{\Sigma}\right \rbrace_{k = 1,\dots, K}.$$

## Inference

In this context, the inference task is twofold:

1. Obtaining maximum likelihood estimate of $\theta$;
2. Retracing the hidden sequence $Z_0,\dots Z_n$ given the observations $Y_{0:n}$.

It is well known that these two tasks are indeed complementary. 
A common way to solve these problems is the Expectation Maximization (EM) algorithm
[@dempster1977maximum]. 
The algorithm is shortly depicted here.

### Comment about notations {-}

In the following, we use the notation $p$ for a generic probability distribution. The law to which it refers is explicit through arguments. For instance $p(y_{0:n} \vert z_{0:n})$ is the p.d.f. of a Gaussian vector, the random vector $Y_{0:n}\vert Z_{0:n}$, and $p(z_t\vert z_{t - 1})$ is the law of the discrete random variable $Z_{t} \vert Z_{t - 1}$ evaluated at $z_t$ and $z_{t -1}$. 
In this context, $p(z_t\vert z_{t - 1}) = \mathbb{P}(Z_t = z_t \vert \lbrace Z_{t-1} = z_{t -1}\rbrace.$


### Likelihood

A straightforward way to compute the likelihood in this model can be obtained, just using the Markov properties of this model:
\begin{align}
L(\theta \vert y_{0:n}) &:= p(y_{0:n} \vert \theta) \nonumber \\
&= \sum_{z_{0:n}} p(y_{0:n}, z_{0:n}) \nonumber \\
&= \sum_{z_{0:n}} p(z_{0:n})p(y_{0:n}\vert z_{0:n}) \nonumber \\
&=  \sum_{z_{0:n}} p(z_0 \vert \theta) p(y_0\vert z_0, \theta) \prod_{t = 1}^n p(z_{t} \vert z_{t - 1}, \theta)p(y_{t}\vert y_{t -1}, z_{t}, \theta)  (\#eq:AR-HMM-likelihood).
\end{align}
For a known $\theta$, every term in \@ref(eq:AR-HMM-likelihood) can be computed.
However, in a general setting, there exists $K^{n + 1}$ possible sequences $z_{0:n}$, which makes this direct computation hardly feasible for any common values of $n$.

### Complete log-likelihood

In the context of missing data problems,  an important function is the *complete log-likelihood*, i.e. the likelihood of the *completed* observations (what we wish we could observe), $(y_{0:n}, z_{0:n})$.
We have that:

\begin{align}
\ell(\theta \vert y_{0:n}, z_{0:n}) :=& \log p(y_{0:n}, z_{0:n} \vert \theta) \nonumber \\
=& \log p(y_{0:n}, z_{0:n}) \nonumber \\
=& \log p(z_{0:n}) + \log p(y_{0:n}\vert z_{0:n}) \nonumber \\
=&  \log p(z_0 \vert \theta) + \log p(y_0\vert z_0, \theta) \nonumber \\ 
&+ \sum_{t = 1}^n \log p(z_{t} \vert z_{t - 1}, \theta) + \sum_{t = 1}^n \log p(y_{t}\vert y_{t -1}, z_{t}, \theta)  (\#eq:AR-HMM-complete-log-likelihood).
\end{align}

We emphasize here that, if the hidden states were known, this complete log-likelihood can could easily be computed.

### Expectation-Maximization algorithm

A workaround to find the maximum likelihood estimate in this context is the EM algorithm. 
For a given set of parameters, say $\theta^{(0)}$, let's consider the following function of $\theta$:

\begin{equation}
Q(\theta \vert \theta^{(0)}) := \mathbb{E}[\ell(\theta \vert Y_{0:n}, Z_{0:n}) \vert Y_{0:n} = y_{0:n}, \theta^{(0)}] (\#eq:E-step-function).
\end{equation}
A first interesting property of this function is that, for a parameter, say, $\theta^{(1)}$:
$$Q(\theta^{(1)} \vert \theta^{(0)}) \geq Q(\theta^{(0)} \vert \theta^{(0)}) \Rightarrow L(\theta^{(1)} \vert y_{0:n}) \geq L(\theta^{(0)} \vert y_{0:n}).$$
This property naturally suggests an algorithm to obtain the MLE in this model:

- **Initialization:** Given a set of observations $y_{0:n}$, set initial guess $\theta^{(0)}$
- **Iteration:** For $k$ in $1,\dots, n$:
    1. **E step**: Compute $Q(\theta \vert \theta^{(k-1)})$;
    2. **M step**: Set $\theta^{(k)} = \text{argmax}_\theta Q(\theta \vert \theta^{(k-1)})$.

It can be shown that the resulting sequence $\lbrace\theta^{(k)} \rbrace_{k \in \mathbb{N}}$ has a non decreasing set of likelihood values, and it converges towards a critical point (i.e., where the gradient of the likelihood is 0).

In this section, one can ask what's the meaning of *computing* $Q(\theta \vert \theta^{(k-1)})$. 
As this function of $\theta$ is an expectation with respect to a discrete distribution (the distribution of missing values conditionnally to the observations, under the parameter $\theta^{(k-1)}$), *computing* this function means to compute the related weights, that depends on the the observations and on $\theta^{(k-1)}$.

Indeed, we have:

\begin{align}
Q(\theta \vert \theta^{(0)}) :=& \mathbb{E}[\ell(\theta \vert Y_{0:n}, Z_{0:n}) \vert Y_{0:n} = y_{0:n}, \theta^{(0)}]\nonumber \\
=& \sum_{z_{0:n}} \ell(\theta \vert y_{0:n}, z_{0:n}) p(z_{0:n} \vert y_{0:n}, \theta^{(0)}) \text{d} z_{0:n} \nonumber \\
=& \sum_{k = 1}^K p(z_0 = k \vert y_{0:n}, \theta^{(0)})\left(\log p(z_0 = k \vert \theta) + \log(p(y_0 \vert z_0 = k, \theta))\right)  \nonumber \\
& + \sum_{k = 1}^K\sum_{k' = 1}^K \sum_{t = 1}^n p(z_{t-1} = k, z_{t} = k'\vert y_{0:n}, \theta^{(0)}) \log p(z_{t} = k' \vert z_{t - 1} = k,\theta) \nonumber \\
& + \sum_{k = 1}^K \sum_{t = 1}^n p(z_t = k\vert y_{0:n}, \theta^{(0)}) \log p(y_{t} \vert z_{t} = k, \theta) \nonumber
\end{align}

### E step, the Baum-Welch smoothing algorithm

The E step requires to compute $p(z_t = k \vert y_{0:n}, \theta^{(0)})$ and 
$p(z_{t - 1} = k, z_{t} = k' \vert y_{0:n}, \theta^{(0)})$.

This is done in an twofold iterative way using the fact that:

\begin{align*}
p(z_t \vert y_{0:n}, \theta^{(0)}) &\propto 
\left\lbrace
\begin{array}{ll}
p(y_{0:t}, z_t \vert{\theta^{(0)}})p(y_{(t+1):n} \vert z_t, y_t, \theta^{(0)})  &~0\leq t < n, \\
p(y_{0:n}, z_n \vert{\theta^{(0)}})&~t = n.
\end{array}
\right. \\
p(z_{t - 1}, z_t \vert y_{0:n}, \theta^{(0)}) &\propto 
\left\lbrace
\begin{array}{ll}
p(y_{0:{t - 1}}, z_{t -1} \vert{\theta^{(0)}}) p(z_{t} \vert z_{t -1}, \theta^{(0)}) p(y_t \vert z_t, \theta^{(0)}) p(y_{(t + 1):n} \vert z_{t }, y_t, \theta^{(0)}),  &~1\leq t < n, \\
p(y_{0:{n - 1}}, z_{n -1} \vert{\theta^{(0)}}) p(z_{n} \vert z_{n -1}, \theta^{(0)})  p(y_n \vert z_n, y_{n -1}, \theta^{(0)}), &~t = n.
\end{array}
\right.
\end{align*}

The key point here is the appearance of two key quantities, $\alpha_t(k) := p(y_{0:{t}}, z_{t} = k \vert{\theta^{(0)}})$ and $\beta_{t}(k) := p(y_{(t+1):n}\vert z_{t} = k, \theta^{(0)})$. To compute these quantities, one can use the following recursions:

* **Forward recursion**:
    - *Initialization*: $$\alpha_0(k) = p(z_0 \vert \theta^{(0)}) p(y_0\vert z_0, \theta^{(0)})$$
    - *Induction*: $$\alpha_t(k) = p(y_t\vert z_t, \theta^{(0)}) \sum_{j = 1}^K \alpha_{t - 1}(j) p(z_t = k\vert z_{t -1} = j, \theta^{(0)})$$
* **Backward recursion**:
    - *Initialization*: $$\beta_n(k) = 1$$
    - *Induction*: $$\beta_t(k) = \sum_{j = 1}^K p(z_{t + 1} = j \vert z_t = k,\theta^{(0)}) p(y_{t+1} \vert z_{t + 1} = j, \theta^{(0)}) \beta_{t+1}(j).$$

It thus remains to perform the M-step.

### M step, constrained optimization and weighted least square 

The goal is now to maximize, with respect to $\theta$, the function:
\begin{align*}
Q(\theta \vert \theta^{(0)})&= \sum_{k = 1}^K p(z_0 = k \vert y_{0:n}, \theta^{(0)})\left(\log p(z_0 = k \vert \theta) + \log(p(y_0 \vert z_0 = k, \theta))\right)  \nonumber \\
& + \sum_{k = 1}^K\sum_{k' = 1}^K \sum_{t = 1}^n p(z_{t-1} = k, z_{t} = k'\vert y_{0:n}, \theta^{(0)}) \log p(z_{t} = k' \vert z_{t - 1} = k,\theta) \nonumber \\
& + \sum_{k = 1}^K \sum_{t = 1}^n p(z_t = k\vert y_{0:n}, \theta^{(0)}) \log p(y_{t} \vert z_{t} = k, \theta), \nonumber
\end{align*}
where all terms that do not depend on $\theta$ are known.

Here, again, we skip the estimation of the terms of $\theta$ related to initial distributions $\chi_{0,Z}$ and $\chi_{0, X}$, which can only be obtained when multiple trajectories (and then initial points) are observed.

We thus focus on updating the transition matrix $\mathbf{P}_{ij},~1\leq i, j \leq K$ and dynamics parameters $\lbrace m(k), \mathbf{A}(k), \mathbf{\Sigma}(k)\rbrace_{k = 1,\dots, K}$.

### Updating $\mathbf{P}$ {-}

We recall that $\mathbf{P} = \left \lbrace\mathbf{P}_{kk'} := p(z_{t} = k' \vert z_{t - 1} = k, \theta) \right\rbrace_{k,k' = 1,\dots, K}$. $\mathbf{P}$ is a stochastic matrix, and then satisfies the $K$ constraints:
$g(\mathbf{P}_{k\bullet}): = \sum_{k'=1}^K P_{kk'} = 1, 1\leq k \leq K$.
Thus, maximizing $Q(\theta \vert \theta^{(0)})$ with respect to $\mathbf{P}$ only requires to focus on the terms
$$\sum_{k' = 1}^K \sum_{t = 1}^ np(z_{t-1} = k, z_{t} = k'\vert y_{0:n}, \theta^{(0)}) \log \mathbf{P}_{kk'} := f(\mathbf{P}_{k\bullet}).$$
Using the Lagrange multiplier method, we want to solve the $K$ systems of $K + 1$ equations:
\begin{align*}
\nabla f(\mathbf{P}_{k\bullet}) &= \lambda_k \nabla g(\mathbf{P}_{k\bullet})\\
g(\mathbf{P}_{k\bullet}) &= 1,
\end{align*}
where $\nabla$ is the gradient operator, and $\lambda_k \in \mathbb{R}^*$ is called the Lagrange multiplier. In this case, we therefore have:
\begin{align*}
\frac{\sum_{t = 1}^n p(z_{t-1} = k, z_{t} = k'\vert y_{0:n}, \theta^{(0)})}{\mathbf{P}_{k,k'}} &= \lambda_k \\
\sum_{k' = 1}^K{\mathbf{P}_{kk'}} &= 1.
\end{align*}
This leads directly to:
\begin{align*}
\lambda_k &= \sum_{t = 1}^n p(z_{t - 1} = k \vert y_{0:n}, \theta^{(0)}) \\
\mathbf{P}_{kk'} &= \frac{\sum_{t = 1}^n p(z_{t - 1} = k, z_{t} = k'\vert y_{0:n}, \theta^{(0)}) }{\sum_{t = 1}^n p(z_{t - 1} = k \vert y_{0:n}, \theta^{(0)})}
\end{align*}

### Updating dynamics parameters {-}

For each $1\leq k \leq K$, our goal is to maximize the terms:
$$\sum_{t = 1}^n p(z_t = k\vert y_{0:n}, \theta^{(0)}) \log p(y_{t} \vert z_{t} = k, \theta).$$
One can recognize here that it is the same linear framework as  \@ref(eq:AR-simple) where a specific weight (the posterior probability of being in $k$ under $\theta^{(0)}$) would be assigned to each observation.
In this context, maximizing in $\theta$ then results in $K$ weighted linear regressions. 

For $1 \leq k\leq K$, updating 
$\mathbf{B}(k) := \begin{pmatrix} m'(k)\\ \mathbf{A}'(k) \end{pmatrix}$ is done using the weighted least square estimator:
$$\widehat{\mathbf{B}}(k) = \left(\mathbf{X}'\mathbf{W}(k)\mathbf{X} \right)^{-1} \mathbf{X}'\mathbf{W}(k) \mathbf{Y},$$
where 
$$\mathbf{W}(k) = \begin{pmatrix}p(z_1 = k\vert y_{0:n}, \theta^{(0)}) & \cdots & 0 \\
\vdots & \ddots & \vdots\\
0 & \cdots & p(z_{n} = k\vert y_{0:n}, \theta^{(0)})
\end{pmatrix}.$$
The estimator of $\Sigma(k)$